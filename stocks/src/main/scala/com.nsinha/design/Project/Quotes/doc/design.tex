\documentclass{beamer}


% Setup appearance:

\usetheme{Darmstadt}
\usefonttheme[onlylarge]{structurebold}
\setbeamerfont*{frametitle}{size=\normalsize, series=\bfseries}
\setbeamertemplate{navigation symbols}{}


% Standard packages

\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage{hyperref}

% Setup TikZ

\usepackage{ifthenx}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{calc}
\usepackage{pgfmath}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{ulem}
\tikzstyle{block}=[draw opacity=0.7, line width=1.4cm]
\lstset{language=C}

% Author, Title, etc.

\title[Anomaly Detection System Overview]
{%
Quotes project
%
}

\author[Sinha N]
{
  Nish~Sinha\inst{1} \and
}

\institute[Xad]
{
  \inst{1}%
  Nsinha Inc.,  CA, USA
  \and
  \vskip-2mm
}

\date[\today]
{\today}



% The main document
\newcommand{\drawBoxVertText}[5]{{0}
		\shade[top color=#4, bottom color=#4,xslant=#5] (#1) rectangle (#2) node[midway,below][label={[rotate=-90]left:#3}] {};

%node[midway][above] [label={[rotate=-90]above:#3}]{};
}

\newcommand {\drawArrowLToRAbove}[3] {
	\draw[->, auto] let
		\p1 = (#1), \p2 = (#2)
		in
		(\x1  ,\y1) -- (\x2,\y2)  
		(\x1  ,\y1) -- (\x2,\y2)  node[midway][above] {#3};
}

\newcommand{\drawLinkArrowVertical}[4]{
	\draw[->, auto] let
		\p1 = (#1), \p2 = (#2),
		\p3 = (#3), \p4 = (#4)
		in
		({(\x1 + \x2)*1/2} ,\y1) -- ({(\x3 + \x4)*1/2} ,\y4);
}

\newcommand{\drawLinkArrowVerticalWithOffset}[4]{
	\draw[->, auto] let
		\p1 = (#1), \p2 = (#2),
		\p3 = (#3), \p4 = (#4)
		in
		(\x1  ,\y1) -- (\x3 ,\y4);
}
\newcommand{\drawLinkArrowHorizontal}[4]{
	\draw[<->] let
		\p1 = (#1), \p2 = (#2),
		\p3 = (#3), \p4 = (#4)
		in
		(\x2, {(\y1 + \y2)*1/2}) -- (\x3, {(\y3 + \y4)*1/2});
}

\newcommand{\drawBox}[5]{{0}
		\shade[top color=#4, bottom color=#4,xslant=#5] (#1) rectangle (#2) node[midway,below] {#3};
}

\newcommand{\drawBoxTextBottom}[7]{{0}
		\shade[top color=#4, bottom color=#4,xslant=#5] (#1) rectangle (#2) node[left=#6in,below=#7in] {#3};
}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}



\section{The Design}

\subsection{Flow Diagram }

\begin{frame}{Quotes}
    \begin{itemize}
	\item Quotes (Scottrade) 
    		\begin{itemize}
			\item DailyQuotes
				This project ingests a daily quote file from scottrade and outputs the deserialized rows in specific format. We may append this deserialized form to an aggregate file.Json Serialization.
			\item ConsumeAllDailyQuotes
				This project can process a whole dir of quotes files using \textbf{DailyQuotes} and append to aggegate file. It uses a metafile to track deduplication.
    		\end{itemize}
	    \end{itemize}
\end{frame}

\begin{frame}{Daily Quote data structure}

    \begin{itemize}
	\item Think of data of all stocks as json file
	\item each data point belongs to a given stock and exchange
    		\begin{itemize}
			\item may contain time zone(utc implicit)
			\item current value at instant
			\item instant time stamp with tags like local,unix,utc,precision
			\item current volume at instant(normally this is day's volume from start of day.
			\item high ,low price
			\item open price and day's start timestamap(us start time only)
			\item day's end timestamp(us end time)
			\item previous working day's start timestamp ,end ts, volume, price,high ,low,open,close,percent change
		\end{itemize}
	\item each attribute has a default start at day. Volume starts with 0.Price starts with last closing price(in case available or current price if not available). Data structure should have this notion when storing. 
	\item a compendium of above data will make a total world. 
	
	\end{itemize}
	
\end{frame}

\begin{frame}{Daily Quote ops on data}

	\begin{itemize}
		\item find the graph on a given dimension
		\item sort data as per time stamp and project attributes 
		\item create csv files on any set of attributes and study it.
	\end{itemize}
\end{frame}


\begin{frame}{Daily Quotes project simplifying assumptions}
	\begin{itemize}
		\item days data instead of hourly data
	
	\end{itemize}
\end{frame}

\begin{frame}{Daily Quote rough implementation flow}
	\begin{itemize}
		\item we ingest a day's data.
		\item we append to an aggergate yearly file and corresponding entry meta file. Metafile is for deduplication.
		\item We can assume we have year loads of files containg day's data for years in past and current. The current year is still getting loaded.

		\item We can analyze these files for specific stock dumps. like dumping the flow data and analyzing it in python etc.
	\end{itemize}
\end{frame}



\end{document}

